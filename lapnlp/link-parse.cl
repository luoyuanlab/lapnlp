;;; -*- Mode: Lisp; Package: late -*-
#|
yluo - 08/16/2018 clean and reorganization
yluo - 06/26/2015 rewrite using asdf framework
yluo - 03/13/2012 add (setf (dirty-annotations doc) t) at places, however, this
       better be automatically triggered when slots of an annotation is updated.
yluo - 03/11/2012 introduce more refined granularity when adding verbs to dict
yluo - 09/12/2010 I feel that abs-sent-annotation is not needed, deprecated.
yluo - 08/25/2010 special handling of idiomatic links in PP-dist-sum
yluo - 08/14/2010 added supp-link-dict and populate-link-dict-hash to 
       dynamically populate Link Grammar's dictionary with lookups from UMLS
       knowledge source.
yluo - 07/12/2010 
psz  - 03/../2010 creation

This is a new implementation of the Lisp calls to the link parser interface, by psz,
March 2010. It uses lower-level interface functions defined by
link-interface and link-util. We need more experimentation to
figure out what parse options work best for the kinds of data we
are trying to process. The LP defaults seem to get no parses for
most sentences in the CHED corpus or the MIMIC corpus, for
example. 

For now, we will simply create LP parse_options structures every
time we need them rather than trying to do any kind of re-use
optimization. Here we define the standard settings returned by a
newly-created LP parse-options structure, and then the specific
options used by the link-parser command-line interface. It uses
three fall-back options to parse a sentence, trying each in turn
until they all fail or one succeeds.

Note: The parameters max_sentence_length and panic_mode are,
according to Linas Vepstas, not really parse_options_parameters
that matter, because they are only used by the command-line interface.
used w->fn, w->sp-pos nad w-sca->sp-agr from umlsize.cl

TODO: 
1. hierarchical parsing.
2. use statistical part of speech taggers to eliminate spurious LP linkages
3. Use OpenNLP parser to eliminate spurious linkages (e.g., generated by ambiguous PP attachment)
4. what prevents LP from parsing incomplete sentence? In dictionary file 
4.0.dict, I changed last [[[()]]] in noun-main-* word rules to [Wd-] to 
bias less against incomplete sentence consisting of a noun phrase, i.e., 
single noun phrase will have a cost of 1 instead of 3. 
5. use UMLS to supplement the link parser word files.?
if you change dict, you need to change both in /usr/local/share and LP's
source directory

|#
(defpackage :late
  (:use :common-lisp :util :link :umlsize)
  (:export "*debug-link-parse*"
		   "*po-defaults*"
		   "*po-normal*"
		   "*po-aggressive*"
		   "*po-panic*"
		   ;;"linksrep" "lp-common" "lp-distinct-list"
		   "link-parse"
		   "link-annotate"
		   ;; "link-parse" ;; duplicate, commented out by Yuan
		   "*h-dict-supp*"
		   "supp-link-dict"
		   "populate-link-dict-hash"
		   "populate-link-supp-dict-hash"
		   "load-link-dict"
		   "PP-dist-sum"
		   "cap-adjust"
		   "link-opennlp-pos-agree"
		   "link-pos-check"
		   "link-pos-dup-rm"
		   "biased-linkage-extract"
		   "biased-link-parse"
		   "hier-link-parse"
		   "analyze-parses"
		   "retry-parses"
		   "untokenized?"
		   "unparsed?"
		   "do-sents"
		   "find-untokenized-sentences"
		   "supp-link-dict-from-table"
		   ))

(in-package :late)

(defparameter *debug-link-parse* 1)

(defparameter *po-defaults*
    '(:all_short_connectors	0
      :allow_null	1
      :cost_model_type	1
      :disjunct_cost	2000 ;; ?
      :display_walls	0
      :islands_ok	0
      :linkage_limit	100
      :max_memory	128000000
      :max_null_count	0
      :max_parse_time	-1
      :min_null_count	0
      :null_block	1
      :screen_width  	79
      :short_length	6
      :verbosity	1)
  "These are the values of the various parse-options for a
    newly-created parse_options structure. This is for informational
    purposes, or can be used to reset a parse_options structure to its
    original state, if we also call parse_options_reset_resources.")

(defparameter *po-normal*
    '(:max_parse_time	30              ; was 30
      :linkage_limit	2000		; was 1000
      :short_length	10
      :disjunct_cost	2
      :min_null_count	0
      :max_null_count	0)
  "Parse_options set for normal processing by the link-parser command
    line interface. These are just the options that differ from the
    defaults.")

(defparameter *po-aggressive*
    '(:max_parse_time	30		; was 30
      :linkage_limit	10000		; was 1000
      :short_length	10
      :disjunct_cost	2
      :min_null_count	1
      :max_null_count	0		;replace by sentence length
      ;:islands_ok       1		;remember to disable, yluo
      )
  "Parse_options set for aggressive processing if *po-normal* did not
    lead to a valid parse. These parameters are the same, except that
    they allow a non-0 null_count.")

(defparameter *po-panic*
    `(:max_parse_time	60
      :linkage_limit	100
      :short_length	6
      :disjunct_cost	3
      :min_null_count	1
      :max_null_count	,+MAX_SENTENCE+
      :islands_ok	1
      :all_short_connectors	1
      )
  "Parse_options set for panic mode if previous settings did not lead
    to a valid parse.  These loosen aggressive settings by allowing
    only short connectors, islands, double the time, etc.")
#|    
 We parse text one sentence at a time, which is the Link Parser's
 only method. LP returns a complex data structure that enumerates
 alternate parses (called linkages) of the sentence and additional
 sub-parses for sentences that contain conjunctions. In an initial
 version of this code, we would store a representation of that
 complete structure as an lp-annotation spanning the entire
 sentence. We also experimented with various means of compacting
 these data, because many of the alternative parses share most of
 their structure, differing mainly in the part of speech attributed
 to a specific word, the correspondingly changed link type
 connecting it to other words, and the points of attachment for
 phrases and clauses. The linksrep representation condenses all the
 links that occur within every linkage into a common set, and saves
 the others, separately for each linkage, in its distinct-list.

 In the current revision, we no longer store such a centralized
 representation of the parse of a sentence, instead storing the set
 of links associated with each word in the parse-node-link annotations (one
 for each token in the sentence). Each such annotation stores all
 the links to the left and to the right of this token. Each such
 link is represented by a linkrep structure that holds the starting
 and ending token index positions (within the sentence) of the
 link, the word and its dotted part of speech interpretation at
 either end of the link, and the link labels from the left and
 right directions plus their intersection. In addition, the
 structure holds the link length, the number of domains, and a
 count of the number of times that this link appears in all the
 parses of the sentence at this token.  This representation clearly
 elides some information (e.g., various parsing "costs") and does
 nor retain information on which links on different tokens appeared
 together in specific linkages.  However, for the features we plan
 to use from this representation, this seems adequate.  The former
 lp-annotation scheme remained as an option under the control of the
 parameter *link-annotation-type*, but is now gone except in comments.

 We don't use this in the current code, because instead we put all
 annotations on parse-node-link instances.

;;;(defstruct (linksrep (:type list)
;;;	    (:conc-name lp-))
;;;  common
;;;  distinct-list)
|#


(defmethod link-parse ((sentence sentence-annotation)
		       &key (show? t)
		       (flush? t)
		       (best-only? nil) ; use the best linkage only
		       (tokenize-only? nil))
  "Parse the sentence represented by the argument
   sentence-annotation. If show? is true, print information on failures
   to parse.  If flush? is :incr, then do not re-parse a sentence if it
   already contains parse-node-link annotations. Otherwise, if true, delete
   such existing annotations."
  (assert (equalp (gtype 'gtoken-type) 'lp-token)
	  ()
	  "Why calling me if you are not dealing lp-token?")
  
  (block parsing
    (let ((existing (annotations-within-spec sentence :type 'lp-token)))
      (cond
       ((and (eq flush? :incr) existing)
	;; we've already parsed this sentence; just return -1 to show we
	;; have skipped it
	-1)
       (t
	(when flush? (delete-annotations existing))
	;; adjust capitalization, yluo
	(with-sentence
	 (sent 
	  (cap-adjust (linearize-sentence (content sentence)))
	  *dict*)
	 ;; Since a change in the link-parser at version 4.5.9,
	 ;; tokenization no longer takes place at the time a sentence is
	 ;; created, because now tokenization can differ depending on some
	 ;; settings of parse_options.  The new API call sentence_split has
	 ;; been introduced to permit tokenization without parsing.
	 ;; However, this does require a parse_options argument.
	 (with-parse-options
	  (normal *po-normal*)
	  (with-parse-options
	   (aggressive *po-aggressive*)
	   (with-parse-options
	    (panic *po-panic*)
	    
	    (multiple-value-bind (val error)
		(sentence_split sent normal)
	      (when (or error (minusp val))
		(format t "~%Unable to tokenize ~a~@[ because of error ~a~]"
			sentence error)
		(return-from parsing nil)))
	    ;; At this point the sentence is tokenized. We extract all but the
	    ;; left- and right-most (which are LEFT-WALL and RIGHT-WALL) and
	    ;; map them to the corresponding places in the document. Alas, LP
	    ;; does not give us the start and end positons of each token, so
	    ;; we use the fact that the tokens must be in order to advance a
	    ;; cursor. If the splitter gets an error or if the sentence
	    ;; has no tokens, we obviously can't extract this information.
	    (let* ((doc (document sentence))
		   (ntok (sentence_length sent))
		   (cursor (start sentence))
		   (limit (end sentence))
		   po tokens nodes
		   ;;(nodes (and (>= ntok 3) (make-array (list (- ntok 2)))))
		   (nparses 0)
		   (linkage-tables nil))
	      (unless (annotations-spec sentence :type 'lp-token)
		(dotimes (i (- ntok 2))
		  (let* ((w (sentence_get_word sent (1+ i)))
			 (pos (search w (content doc)
				      :start2 cursor :end2 limit
				      :test #'char-equal)))
		    (when (null pos)
		      (error "LP tokenization failed, at word ~d (~a) in ~s"
			     (1+ i) w sentence))
		    (setq cursor (+ pos (length w)))
		    (let (;; We store the word number, for coordination
			  ;; with the linkage table data, below.
			  ;; The left and right k-tuples will be added below.
			  (ann (make-instance 'lp-token
					      :document doc
					      :start pos
					      :end (+ pos (length w))
					      :sw-ver (gsw-ver 'gtokenize)
					      :setting (gsetting 'gtokenize))))
		      (unless (in-no-token-area? ann)
			(push ann tokens)
			(add-annotation doc ann)
			(add-annotation sentence ann)))))
		(setf tokens (nreverse tokens)))

	      (unless tokenize-only?
		(assert (equalp (gtype 'gparse-node-type) 
				'parse-node-link-reg)
			()
			"Why call me if not handling parse-node-link-reg?")
		(dolist (token tokens)
		  (let (;; We store the word number, for coordination
			;; with the linkage table data, below.
			;; The left and right k-tuples will be added below.
			(ann (make-instance 'parse-node-link-reg
					    :document doc
					    :start (start token)
					    :end (end token)
					    :data (content token)
					    :sw-ver (gsw-ver 'gparse)
					    :setting (gsetting 'gparse))))
		    (push ann nodes)
		    (add-annotation doc ann)
		    (add-annotation sentence ann)))
		(setf nodes (nreverse nodes))
		(setq nparses
		      (ignore-errors (sentence_parse sent (setq po normal))))

		(when (or (null nparses) (minusp nparses))
		  ;; nparses can be -1 in case of error
		  (when show?
		    (format t "~%Error occurred parsing ~s with ~a options."
			    sentence 'normal)))
		(unless (and nparses (> nparses 0))
		  (parse_options_set_max_null_count
		   aggressive (sentence_length sent))
		  (setq nparses
			(ignore-errors
			  (sentence_parse sent (setq po aggressive))))
		  (when (or (null nparses) (minusp nparses))
		    (when show?
		      (format t "~%Error occurred parsing ~s with ~a options."
			      sentence 'aggressive)))
		  (unless (and nparses (> nparses 0))
		    (setq nparses
			  (ignore-errors
			    (sentence_parse sent (setq po panic))))
		    (when (or (null nparses) (minusp nparses))
		      (when show?
			(format t "~%Error occurred parsing ~s with ~a options."
				sentence 'panic)))))
		(cond
		 ((or (null nparses) (minusp nparses))
		  ;; already reported error
		  -1)
		 ((zerop nparses)
		  (when show?
		    (format t "~%No parses found for ~s" sentence))
		  0)
		 (t (dotimes (pnum (if best-only? 1 nparses))
		      (with-linkage
		       (linkage pnum sent po)
		       ;; This computes a combined linkage in case the
		       ;; sentence/linkage contains conjuncts.
		       (linkage_compute_union linkage)
		       (let ((nsublinkages
			      (linkage_get_num_sublinkages linkage)))
			 (linkage_set_current_sublinkage
			  linkage (1- nsublinkages))
			 (let ((lt (link-table linkage)))
			   (when lt (push lt linkage-tables))))))
		    (cond
		     (linkage-tables
		      ;;(push linkage-tables *lt*) ; for debugging
		      (link-annotate linkage-tables nodes)
		      (if best-only? 1 nparses))
		     (t 0)))))))))))))))

;;(defparameter *link-annotation-type* '(token-ntuples))

(defun link-annotate (linkage-tables nodes)
  "Creates annotations from the linkages computed by the link parser.
  Because we are yet unsure what are the best annotations to create,
  this depends on the global setting of *link-annotation-type*."
  (when t ;;(member 'token-ntuples *link-annotation-type*)
    ;; This annotation-type records, for each parse-node-link, all of its
    ;; left and right linkages from all of the parses found by lp.
    ;; Note that in general this may result in multiple instances of
    ;; the same linkage (e.g., from different parses)
    (dolist (lt linkage-tables)
      (dolist (l lt)
	;; Note that nodes are indexed in links by 1..n because LEFT
	;; and RIGHT walls are 0 and n+1!
	(when (plusp (l-lindex l))		;omit linkages to LEFT-WALL
	  (push l (right-links (elt nodes (1- (l-lindex l))))))
	(when (< (l-rindex l) (length nodes)) ;or RIGHT_WALL
	  (push l (left-links (elt nodes (1- (l-rindex l))))))))
    ;; Now post-process the set of links on each token to identify
    ;; and eliminate duplicates and just keep a count. This should
    ;; compress the data considerably. We might also think about
    ;; generalizing link-labels, so that for example A and AN links,
    ;; which often occur as alternatives, are unified; not yet.
    (dolist (node nodes)
      (labels
	  ((condense (list-of-links &aux (ans nil))
		     (dolist (l list-of-links)
		       (let ((old (member l ans :test #'l=)))
			 (if old (incf (l-copies (car old)))
			   (push l ans))))
		     ans))
	(setf (left-links node) (condense (left-links node)))
	(setf (right-links node) (condense (right-links node)))
	(setf (dirty node) t)))))

;;; for example, tablized sections do not need to be parsed.
(defmethod link-parse ((doc document)
		       &key (show? nil)
		       (flush? t)
		       (best-only? nil)
		       (tokenize-only? nil))
  (assert (equalp (gtype 'gparse-node-type) 'parse-node-link)
	  ()
	  "Why calling me if you are not handling parse-node-link?")
  (when show?
    (format t "~%Parsing ~a" doc))
  (when (and flush? (not (eq flush? :incr)))
    ;; Flush lp-related annotations wholesale, not per sentence.
    (flush-annotations-spec doc :type 'parse-node-link))
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (sa (annotations doc :type 'sentence-annotation))
      (let ((parsed (link-parse sa
				:show? show?
				:flush? (and (eq flush? :incr) :incr)
				:best-only? best-only?
				:tokenize-only? tokenize-only?)))
	(cond ((null parsed) (incf n-err))
	      ((and (numberp parsed) (zerop parsed)) (incf n-lose))
	      ((and (numberp parsed) (minusp parsed)) (incf n-skipped))
	      (t (incf n-win)))))
    (add-analysis doc :ganalysis 'gtokenize) 
    
    (cond
     (tokenize-only?
      (populate-link-supp-dict-hash doc))
     (t
      (add-analysis doc :ganalysis 'gparse)))
    (save doc)
    (list n-win n-lose n-err n-skipped)))

(defmethod link-parse ((corp corpus)
		       &key (show? t)
		       (flush? t)
		       (best-only? nil)
		       (tokenize-only? nil))
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (dn (documents corp))
      (let ((result
	     (link-parse (document dn)
			 :show? show?
			 :flush? flush?
			 :best-only? best-only?
			 :tokenize-only? tokenize-only?)))
	(incf n-win (car result))
	(incf n-lose (cadr result))
	(incf n-err (caddr result))
	(incf n-skipped (cadddr result))))
    (list n-win n-lose n-err n-skipped)))

(defmethod link-parse ((sentence string)
		       &key (show? t)
		       (flush? t)
		       (best-only? nil) ; not used?
		       (tokenize-only? nil))
  "For debugging: Parse the sentence given by its argument. Returns vector of
   tokens and a list of linkage-tables, or 0 if no parses."
  (declare (ignore flush?) (ignorable best-only?))
  (block parsing
    ;; (cap-adjust (linearize-sentence 
    (with-sentence
     (sent (cap-adjust (linearize-sentence sentence)) *dict*)
     (with-parse-options
      (normal *po-normal*)
      (with-parse-options
       (aggressive *po-aggressive*)
       (with-parse-options
	(panic *po-panic*)
	(multiple-value-bind (val error)
	    (sentence_split sent normal)
	  (format t "~%sentence_split returned ~a" val)
	  (when (or error (minusp val))
	    (format t "~%Unable to tokenize ~a~@[ because of error ~a~]"
		    sentence error)
	    (return-from parsing nil)))
	(let* ((ntok (sentence_length sent))
	       (po nil)
	       (tokens (and (>= ntok 3) (make-array (list (- ntok 2)))))
	       (nparses 0)
	       (linkage-tables nil))
	  (dotimes (i (- ntok 2))
	    (setf (aref tokens i) (sentence_get_word sent (1+ i))))
	  (unless tokenize-only?
	    ;; added reset, yluo
	    (parse_options_reset_resources (setq po normal))
	    (setq nparses
		  (ignore-errors (sentence_parse sent po)))
	    (when (or (null nparses) (minusp nparses))
	      ;; nparses can be -1 in case of error
	      (when show?
		(format t "~%Error occurred parsing ~s with ~a options."
			sentence 'normal)))
	    (unless (and nparses (> nparses 0))
	      (parse_options_set_max_null_count
	       aggressive (sentence_length sent))
	      (format t "~&aggressive parsing~%")
	      (setq nparses
		    (ignore-errors
		      (sentence_parse sent (setq po aggressive))))
	      (when (or (null nparses) (minusp nparses))
		(when show?
		  (format t "~%Error occurred parsing ~s with ~a options."
			  sentence 'aggressive)))
	      (unless (and nparses (> nparses 0))
		(setq nparses
		      (ignore-errors
			(sentence_parse sent (setq po panic))))
		(format t "~&panic parsing~%")
		(when (or (null nparses) (minusp nparses))
		  (when show?
		    (format t "~%Error occurred parsing ~s with ~a options."
			    sentence 'panic))))))
	  (cond
	   ((or (null nparses) (minusp nparses))
	    ;; already reported error
	    )
	   ((zerop nparses)
	    (when (and show? (not tokenize-only?))
	      (format t "~%No parses found for ~s" sentence))
	    (values tokens 0))
	   (t (dotimes (pnum nparses)
		(with-linkage
		 (linkage pnum sent po)
		 ;; This computes a combined linkage in case the
		 ;; sentence/linkage contains conjuncts.
		 (linkage_compute_union linkage)
		 (let ((nsublinkages
			(linkage_get_num_sublinkages linkage))
		       diagram)
		   (linkage_set_current_sublinkage
		    linkage (1- nsublinkages))
		   (setf diagram (linkage_print_diagram linkage))
		   (format t "~&~a~%" (native-to-string diagram))
		   (linkage_free_diagram diagram)			
		   (let ((lt (link-table linkage)))
		     (when lt
		       (format t "~&PP dist sum is: ~a~%" (PP-dist-sum lt))
		       (push lt linkage-tables))))))
	      (values tokens (or linkage-tables 0)))))))))))



(defparameter *h-dict-supp* (make-hash-table :test #'equalp))

(defmethod supp-link-dict ()
  "write extra words into dictionary files from hash table,
This function cannot work in parallel!"
  (assert *link-work*
	  ()
	  "you must specify *link-work* and it shouldn't be same as *link-home*")
  (maphash #'(lambda (fn-word l-word)
	       (mapcar #'(lambda (w) 
			   (pushnew fn-word (gethash w *h-dict*) 
				    :test #'string=)) 
		       l-word)
	       (format t "~&[~a] supplement to ~a:~% ~{~a~^~%~}~%" 
		       (sys-time-str) fn-word l-word)
	       ;; should use merge pathname
	       (setf fn-word (merge-pathnames
			      (make-pathname :directory '(:relative "en" "words")
					     :name fn-word)
			      *link-work*))
	       (with-open-file (f-word fn-word 
				       :direction :output :if-exists :append
				       :if-does-not-exist :create)
			       (format f-word "~&~{~a~^~%~}~%" l-word)))
	   *h-dict-supp*)
  ;; after write to file, clear hash table
  (clrhash *h-dict-supp*))

(defmethod supp-link-dict-from-table ()
  "write extra words into dictionary files from database table, 
This function cannot work in parallel!"
  (assert *link-work*
	  ()
	  "you must specify *link-work* and it shouldn't be same as *link-home*")
  (mapcar #'(lambda (x)
	      (let* ((fn-word (car x))
		     (word (nth 1 x)))
		(setf fn-word (merge-pathnames
			       (make-pathname :directory '(:relative "en" "words")
					      :name fn-word)
			       *link-work*))
		(with-open-file (f-word fn-word 
					:direction :output :if-exists :append
					:if-does-not-exist :create)
				(format f-word "~&~a~%" word))
		
		(format t "~&[~a] supplement to ~a: ~a~%" 
			(sys-time-str) fn-word word)))
	  (latesql "SELECT file, entry FROM link_supp_dict"))
  ;; after write to file, clear table
  (latesql "DELETE FROM link_supp_dict"))

(defun load-link-dict (&key (reload? nil))
  (when reload?
    (format t "~&Loading latest link dict~%")
    (when *dict*
      (dictionary_delete *dict*))
    ;; ok to put both supplement methods here, because if supplemnting from hash
    ;; the values won't be in the database tables yet, while if supplementing
    ;; from database tables , corresponding data in the hash table are already 
    ;; purged
    (supp-link-dict)
    (supp-link-dict-from-table)
    (populate-link-dict-hash *link-dict-list*))
  (if *dict*
      (format t "~&Not reloading already loaded link dict~%")
    (setf *dict* (dict-create (namestring *dict-n*)
			      (namestring *know-n*)
			      (namestring *post-n*)
			      (namestring *affix-n*)))
    ;;(setf *dict* (dictionary_create_lang "en"))
    ))

(defun reload-link-dict ()
  (when *dict*
    (dictionary_delete *dict*))
  ;; ok to put both supplement methods here, because if supplemnting from hash
  ;; the values won't be in the database tables yet, while if supplementing
  ;; from database tables , corresponding data in the hash table are already 
  ;; purged
  (supp-link-dict)
  (supp-link-dict-from-table)
  (populate-link-dict-hash *link-dict-list*)
  (setf *dict* (dict-create (namestring *dict-n*)
			    (namestring *know-n*)
			    (namestring *post-n*)
			    (namestring *affix-n*)))
  ;;(setf *dict* (dictionary_create_lang "en"))
  )

(defun push-str-var (pos str afile tfiles cfiles)
  "Push str into the to-be-supplemented list of the associated file, if needed.
Input
======
pos: pos tag
str: the word
afile: the file that word is to be inserted if it is not present
tfiles: target files to search the word 'str' for presence
cfiles: current files that the word 'str' is in
Note
======
The associated file is taken to be the first of the tfiles list.
As far as yluo tested, direct pushnew to hash table works."
  (unless (intersection tfiles cfiles :test #'string=)
    (pushnew (format nil "~a~a" str pos) 
	     (gethash afile *h-dict-supp*)
	     :test 'string=)
    (pushnew (format nil "~a~a" (string-downcase str) pos) 
	     (gethash afile *h-dict-supp*)
	     :test 'string=)))

(defun in-4.0.dict (word tposes &aux dicts)
  "Predicates whether word with targeted pos tags (tposes) appear in 4.0.dict."
  (setf dicts (gethash word *h-dict*))
  (intersection dicts (mapcar #'(lambda (x) (format nil "4.0.dict~a" x)) tposes)
		:test #'string=))

(defun umls-lword-catp (word cat sp-pos &aux agrs)
  "link word category predicate through umls
Test if a word with sp-pos (umls specialist lexicon pos tag) should be 
categorized into a link words dictionary"
  (setf agrs (w-sca->sp-agr word sp-pos))
  (cond
   ((equalp cat "words.n.4")
    ;; count(thr_plur) count(thr_sing) uncount(thr_sing) uncount(thr_plur)
    nil
    ;; see comments in 4.0.dict for 4.7.4
    ;; words.n.4: nouns that can be mass or countable
    ;; allocation.n allotment.n alloy.n allure.n alteration.n alternation.n 
    ;; piano.n flute.n belong here, because of "He plays piano"
    ;; This class has now been eliminated: nouns are either singular, plural
    ;; or mass. If they can be more than one, then they are listed separately
    ;; in each class e.g. words.n.1 and/or words.n.2 and/or words.n.3, etc.
    ;; (and (or (member "uncount(thr_sing)" agrs :test #'string=)
    ;; 			 (member "uncount(thr_plur)" agrs :test #'string=))
    ;; 		 (or (member "count(thr_sing)" agrs :test #'string=)
    ;; 			 (member "count(thr_plur)" agrs :test #'string=)))
    )
   
   ((equalp cat "words.n.1")
    (member "count(thr_sing)" agrs :test #'string=))
   
   ((equalp cat "words.n.2.s")
    (and (member "count(thr_plur)" agrs :test #'string=)
	 (match-re "s$" word)))
   
   ((equalp cat "words.n.2.x")
    (and (member "count(thr_plur)" agrs :test #'string=)
	 (not (match-re "s$" word))))
   
   ((equalp cat "words.n.3")
    (or (member "uncount(thr_sing)" agrs :test #'string=)
	(member "uncount(thr_plur)" agrs :test #'string=)))
   
   ;; past_part past pres_part pres(thr_sing) infinitive 
   ;; pres(fst_sing,fst_plur,thr_plur,second)
   ;; treat all not-in-dict verbs as optionally transitive
   
   ;; intransitive
   ((equalp cat "words.v.1.3")
    (and (intranp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.1.4")
    (and (intranp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.1.2")
    (and (intranp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.1.1")
    (and (intranp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))

   ;; optionally transitive
   ((equalp cat "words.v.2.3")
    (and (opt-tranp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.2.4")
    (and (opt-tranp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.2.5")
    (and (opt-tranp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.2.2")
    (and (opt-tranp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.2.1")
    (and (opt-tranp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))

   
   ;; transitive
   ((equalp cat "words.v.4.3")
    (and (tranp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.4.4")
    (and (tranp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.4.5")
    (and (tranp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.4.2")
    (and (tranp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.4.1")
    (and (tranp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))
   
   ;; intransitive, two word
   ((equalp cat "words.v.5.3")
    (and (intran-partp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.5.4")
    (and (intran-partp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.5.2")
    (and (intran-partp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.5.1")
    (and (intran-partp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))
   
   ;; optionally transitive, two word
   ((equalp cat "words.v.6.3")
    (and (opt-tran-partp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.6.4")
    (and (opt-tran-partp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.6.5")
    (and (opt-tran-partp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.6.2")
    (and (opt-tran-partp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.6.1")
    (and (opt-tran-partp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))

   ;; transitive, two word
   ((equalp cat "words.v.8.3")
    (and (tran-partp word)
	 (or (member "past_part" agrs :test 'string=)
	     (member "past" agrs :test 'string=))))
   
   ((equalp cat "words.v.8.4")
    (and (tran-partp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.8.5")
    (and (tran-partp word)
	 (member "pres_part" agrs :test 'string=)))
   
   ((equalp cat "words.v.8.2")
    (and (tran-partp word)
	 (member "pres(thr_sing)" agrs :test #'string=)))
   
   ((equalp cat "words.v.8.1")
    (and (tran-partp word)
	 (or (member "infinitive" agrs :test #'string=)
	     (member "pres(fst_sing,fst_plur,thr_plur,second)" agrs 
		     :test #'string=))))
   
   
   ;;positive positive;periph comparative superlative
   ((equalp cat "words.adj.1")
    (or (member "positive" agrs :test #'string=)
	(member "positive;periph" agrs :test #'string=)))
   
   ((equalp cat "words.adj.2")
    (member "comparative" agrs :test #'string=))
   
   ((equalp cat "words.adj.3")
    (member "superlative" agrs :test #'string=))
   
   ;; positive positive;periph comparative superlative. due to link grammar's 
   ;; specific categorization, we treat all new adv. as ordinary
   ((equalp cat "words.adv.1")
    (intersection '("positive" "positive;periph" "comparative" "superlative")
		  agrs :test #'string=))
   ))

(defmethod populate-link-supp-dict-hash ((doc document))
  "In theory, I have added every possible word pos combination based on UMLS
here; but the leveraging LVG in tagize part is limited..."
  ;; (declare (optimize (speed 1) (safety 1) (space 1) (debug 3)))
  (assert (equalp (gtype 'gtoken-type) 'lp-token)
	  ()
	  "Why calling me if you are not hanlding lp-token?")
  (dolist (sa (annotations doc :type 'sentence-annotation))
    ;; need to exclude parse-node-link
    (let* ((tas (annotations-spec sa :type 'lp-token)))
      (dotimes (i (length tas))
	(let* ((ta (elt tas i))
	       (ta-str (content ta)) ; (string-downcase (content ta))
	       (ta-dicts (gethash ta-str *h-dict*))
	       (sp-poses (w->sp-pos ta-str))
	       (tnposes '(".b" ".c" ".f" ".i" ".l" ".m" ".n" ".n-u" ".o" ".s" 
			  ".t" ".u" ".x" "" ".y")) ; target noun poses
	       (tvposes '(".q" ".w" ".q-d" ".v-d" ".w-d" ".v" ".g" ""))
	       (taposes '(".a" ".a-c" ".a-s" ""))
	       (trposes '(".e" ".r" ""))
	       tdicts)

	  (when (intersection sp-poses *sp-lex-fn-scas* :test #'equal)
	    (go end))			; lisp doesn't have continue keyword
	  
	  
	  ;; if the noun is not in dictionary.
	  (when (and (member "noun" sp-poses :test #'string=)
		     (not (in-4.0.dict ta-str tnposes))) 

	    ;; have to assume that ta-str is not garbled by weird punctuations,
	    ;; e.g., ?biopsy, thus preprocessing necessary
	    ;; correct even if norm-ta-str doesn't occur in corpora, but choose 
	    ;; to lazy add
	    ;; words.n.4 is deprecated
	    (when (umls-lword-catp ta-str "words.n.4" "noun")
	      (push-str-var ".n" ta-str "words.n.4" '("words.n.4") ta-dicts))

	    (when (umls-lword-catp ta-str "words.n.1" "noun")

	      (push-str-var ".s" ta-str "words.n.1" '("words.n.1" "words.n.1.wiki") 
			    ta-dicts))

	    ;; have some cross over between words.n.2.s and words.n.2.x
	    (when (umls-lword-catp ta-str "words.n.2.s" "noun")
	      (setf tdicts '("words.n.2.s" "words.n.2.s.biolg" "words.n.2.s.wiki"
			     "words.n.2.x" "words.n.2.x.wiki"))
	      (push-str-var ".n" ta-str "words.n.2.s" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.n.2.x" "noun")
	      (setf tdicts '("words.n.2.x" "words.n.2.x.wiki"
			     "words.n.2.s" "words.n.2.s.biolg" "words.n.2.s.wiki"))
	      (push-str-var ".p" ta-str "words.n.2.x" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.n.3" "noun")
	      (push-str-var ".n-u" ta-str "words.n.3" '("words.n.3" ) ta-dicts)))
	  
	  ;; if the verb is not in dictionary
	  (when (and (member "verb" sp-poses :test #'string=)
		     (not (in-4.0.dict ta-str tvposes)))

	    ;; inflection can be relatively certain, while tran/intran/ditran (two word)
	    ;; can be messy, if LGP already categorized tran/intran/ditran, leave it 
	    ;; as is for now
	    ;; past or past participle
	    (setf tdicts '("words.v.1.3" "words.v.2.3" "words.v.4.3" 
			   "words.v.5.3" "words.v.6.3" "words.v.8.3"
			   "words.v.10.3" "words-medical.v.4.3"))
	    (when (umls-lword-catp ta-str "words.v.2.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.2.3" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.1.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.1.3" tdicts ta-dicts))

	    (when (umls-lword-catp ta-str "words.v.4.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.4.3" tdicts ta-dicts))

	    (when (umls-lword-catp ta-str "words.v.5.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.5.3" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.6.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.6.3" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.8.3" "verb")
	      (push-str-var ".v-d" ta-str "words.v.8.3" tdicts ta-dicts))
	    
	    ;; present participle
	    (setf tdicts '("words.v.2.4" "words.v.1.4" "words.v.4.4" 
			   "words.v.5.4" "words.v.6.4" "words.v.8.4"
			   "words.v.10.4" "words-medical.v.4.4"))
	    (when (umls-lword-catp ta-str "words.v.1.4" "verb")
	      (push-str-var ".v" ta-str "words.v.1.4" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.2.4" "verb")
	      (push-str-var ".v" ta-str "words.v.2.4" tdicts ta-dicts))

	    (when (umls-lword-catp ta-str "words.v.4.4" "verb")
	      (push-str-var ".v" ta-str "words.v.4.4" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.5.4" "verb")
	      (push-str-var ".v" ta-str "words.v.5.4" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.6.4" "verb")
	      (push-str-var ".v" ta-str "words.v.6.4" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.8.4" "verb")
	      (push-str-var ".v" ta-str "words.v.8.4" tdicts ta-dicts))		
	    
	    ;; gerund
	    (setf tdicts '("words.v.2.5" "words.v.1.5" "words.v.4.5" 
			   "words.v.5.4" "words.v.6.5" "words.v.8.5"
			   "words.v.10.5" "words-medical.v.4.5"))
	    (when (umls-lword-catp ta-str "words.v.2.5" "verb")
	      (push-str-var ".g" ta-str "words.v.2.5" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.4.5" "verb")
	      (push-str-var ".g" ta-str "words.v.4.5" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.6.5" "verb")
	      (push-str-var ".g" ta-str "words.v.6.5" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.8.5" "verb")
	      (push-str-var ".g" ta-str "words.v.8.5" tdicts ta-dicts))
	    
	    ;; singular
	    (setf tdicts '("words.v.2.2" "words.v.1.2" "words.v.4.2" 
			   "words.v.5.2" "words.v.6.2" "words.v.8.2"
			   "words.v.10.2" "words-medical.v.4.2"))
	    (when (umls-lword-catp ta-str "words.v.1.2" "verb")
	      (push-str-var ".v" ta-str "words.v.1.2" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.2.2" "verb")
	      (push-str-var ".v" ta-str "words.v.2.2" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.4.2" "verb")
	      (push-str-var ".v" ta-str "words.v.4.2" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.5.2" "verb")
	      (push-str-var ".v" ta-str "words.v.5.2" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.6.2" "verb")
	      (push-str-var ".v" ta-str "words.v.6.2" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.8.2" "verb")
	      (push-str-var ".v" ta-str "words.v.8.2" tdicts ta-dicts))		

	    
	    ;; infinitive-plural
	    (setf tdicts '("words.v.2.1" "words.v.1.1" "words.v.4.1" 
			   "words.v.5.1" "words.v.6.1" "words.v.8.1"
			   "words.v.10.1" "words-medical.v.4.1"))
	    (when (umls-lword-catp ta-str "words.v.1.1" "verb")
	      (push-str-var ".v" ta-str "words.v.1.1" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.2.1" "verb")
	      (push-str-var ".v" ta-str "words.v.2.1" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.4.1" "verb")
	      (push-str-var ".v" ta-str "words.v.4.1" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.5.1" "verb")
	      (push-str-var ".v" ta-str "words.v.5.1" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.6.1" "verb")
	      (push-str-var ".v" ta-str "words.v.6.1" tdicts ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.v.8.1" "verb")
	      (push-str-var ".v" ta-str "words.v.8.1" tdicts ta-dicts))
	    )
	  
	  ;; if the adj. is not in dictionary
	  (when (and (member "adj" sp-poses :test #'string=)
		     (not (in-4.0.dict ta-str taposes)))

	    (when (umls-lword-catp ta-str "words.adj.1" "adj")
	      (push-str-var ".a" ta-str "words.adj.1" '("words.adj.1") ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.adj.2" "adj")
	      (push-str-var ".a-c" ta-str "words.adj.2" '("words.adj.2") ta-dicts))
	    
	    (when (umls-lword-catp ta-str "words.adj.3" "adj")
	      (push-str-var ".a-s" ta-str "words.adj.3" '("words.adj.3") ta-dicts)))
	  
	  ;; if the adv. is not in dictionary, but LGP isn't so clear on adv.'s
	  (when (and (member "adv" sp-poses :test #'string=)
		     (not (in-4.0.dict ta-str trposes)))
	    (when (umls-lword-catp ta-str "words.adv.1" "adv")
	      (setf tdicts '("words.adv.1" "words.adv.2" "words.adv.3"
			     "words.adv.4" "words-medical.adv.1"))
	      ;; you have to append .e here, otherwise, link grammar will report
	      ;; duplicate entries upon seeing smaller in words.adv.1 and knowing
	      ;; smaller.a-c in words.adj.2
	      (push-str-var ".e" ta-str "words.adv.1" tdicts ta-dicts))))
	end))))


(defmethod cap-adjust ((sent string))
  "how to preserve the capitalization of special terminology"
  (let* ((words (split-re "\\s+" sent))
	 ans word)
    (dotimes (i (length words))
      (setf word (elt words i))
      (cond 
       ((= 0 i)
	(if (match-re "[a-z]" sent)
	    (setf ans (string-capitalize word))
	  (setf ans word)))
       ((and (= 1 (boolean_abridged_lookup_list *dict* word))
	     (match-re "[a-z]" sent)  (match-re "[A-Z]" sent))
	(setf ans (concatenate 'string ans " " word)))
       ;; bias: downcase > capitalize > uppercase
       ((= 1 (boolean_abridged_lookup_list *dict* (string-downcase word)))
	(setf ans (concatenate 'string ans " " (string-downcase word))))
       ((= 1 (boolean_abridged_lookup_list *dict* (string-capitalize word)))
	(setf ans (concatenate 'string ans " " (string-capitalize word))))
       (t
	(setf ans (concatenate 'string ans " " word)))))
    ans))

(defun PP-dist-sum (lt)
  "Sums up the total distance of prep links that connect a prep. to a left
token, excluding idiomatic prep links. This is meant to be used as a heuristic
bias to select the linkages.
If you want to focus on prep modifying nouns, use the following as filter:
;; (match-re \"^M[^A-Z]*$\" (l-lab line)) ; only care about Mp
"
  (let* ((len 0)
	 sp-poses)
    (dolist (line lt)
      (setf sp-poses (w->sp-pos (replace-re (l-rword line) "\\..*" "")))
      (when (and (member "prep" sp-poses :test #'string=)
		 (not (match-re "^ID" (l-lab line)))
		 (not (match-re "^K" (l-lab line))))			
	(incf len (l-len line))))
    ;;len
    ;; now returns a dummy 1, since we want to disable it.
    1))

(defun link-opennlp-pos-agree (word-pos pos)
  "Predicate to test whether link grammar pos tag agrees with that of opennlp.
Input
======
word: link parser word
pos: opennlp pos tag
"
  (if (null pos)
      ;; LEFT-WALL would have no pos
      (return-from link-opennlp-pos-agree t))
  (multiple-value-bind (match? word link-pos)
      (match-re "[^.]*\\.([^.]*)" word-pos)
    (declare (ignore word))
    (cond 
     (match?
      (cond 
       ((string= link-pos "a")
	(string= pos "JJ"))
       ((string= link-pos "a-c")
	(string= pos "JJR"))
       ((string= link-pos "a-s")
	(string= pos "JJS"))
       
       ;; ignore p, link grammar pos-tag is so messy!
       ((member link-pos 
		'("b" "c" "f" "i" "l" "m" "n" "n-u" "o" "s" "t" "u" "x" "y" 
		  "id" "p") 
		:test #'string=)
	(member pos '("NN" "NNS" "NNP" "NNPS" "CD") :test #'string=))
       
       ((member link-pos '("e") :test #'string=)
	(member pos '("RB" "RBR" "RBS" "WRB") :test #'string=))
       
       ((string= link-pos "g")
	(string= pos "VBG"))
       
       ;; .id ignored
       ((string= link-pos "ij")
	(string= pos "UH"))
       
       ;; conjunctions ignored
       ((member link-pos '("q" "w" "q-d" "v-d" "w-d" "v") :test #'string=)
	(member pos '("VB" "VBD" "VBG" "VBN" "VBP" "VBZ" "MD") :test #'string=))

       (t					 ;; ignored, default to true
	t)))
     (t						 ;; unmarked, who knows?
      t))))

(defun link-pos-check (lt check? poss &aux posa)
  "Given linkage table 'lt' and opennlp pos tag sequence, if check? is true, 
then performing link grammar pos and opennlp pos agreement check for each 
matching pair in 'lt' and 'poss'.
Input
======
lt: linkage table
check?: whether to perform the check
poss: opennlp pos tag string sequence"
  (setf posa (make-array (length poss) :initial-contents poss))
  (cond
   (check?
    (do ((lines lt (cdr lines)))
	((null lines))
      (let* ((line (car lines))
	     (lword-pos (l-lword line))
	     (rword-pos (l-rword line))
	     lpos rpos)
	(unless (string= lword-pos "LEFT-WALL")
	  (setf lpos (aref posa (1- (l-lindex line)))))
	(unless (string= rword-pos "RIGHT-WALL")
	  (setf rpos (aref posa (1- (l-rindex line)))))
	(unless (and (link-opennlp-pos-agree lword-pos lpos)
		     (link-opennlp-pos-agree rword-pos rpos))
	  (return-from link-pos-check nil))))
    lt)
   (t 
    lt)))

(defun link-pos-dup-rm (lt dup-rm? h-noun-pos)
  "the result of this step is that it will always return the first linkage.
Status
======
hack
Note
======
h-noun-pos-loc is a local version of h-noun-pos, both of which take word 
position as key and pos tag as value
for gerund + noun, assume it is always O link, because opennlp would chunk 
gerund into noun phrase otherwise
	  (when (and (member lpos (list 'g') :test #'string=)
		     (member rpos (list 'b' 'c' 'f' 'i' 'l' 'm' 'n' 'n-u' 'o' 
					's' 't' 'u' 'x' 'y') :test #'string=)
		     (not (match-re '^O[^A-Z]*' (l-lab line))))
	    (return nil))
"
  (let* ((h-noun-pos-loc (make-hash-table :test #'equalp)))
    (cond
     (dup-rm?
      (do ((lines lt (cdr lines)))
	  ((null lines))
	(let* ((line (car lines))
	       (lindex (l-lindex line))
	       (lword-pos (l-lword line))
	       (rindex (l-rindex line))
	       (rword-pos (l-rword line))
	       lpos
	       rpos)
	  (multiple-value-bind (match? word link-pos)
	      (match-re "[^.]*\\.([^.]*)" lword-pos)
	    (declare (ignore word match?))
	    (setf lpos (or link-pos "")))
	  (multiple-value-bind (match? word link-pos)
	      (match-re "[^.]*\\.([^.]*)" rword-pos)
	    (declare (ignore word match?))
	    (setf rpos (or link-pos "")))
	  
	  (when (and (null (gethash lindex h-noun-pos-loc))
		     lpos 
		     (member lpos (list "s" "n-u" "n" "") :test #'string=))
	    (cond 
	     ((and (gethash lindex h-noun-pos)
		   (member (gethash lindex h-noun-pos)
			   (list "s" "n-u" "n" "") :test #'string=)
		   (not (string= (gethash lindex h-noun-pos) lpos)))
	      (return-from link-pos-dup-rm nil))
	     (t
	      (setf (gethash lindex h-noun-pos-loc) lpos))))
	  (when (and (null (gethash rindex h-noun-pos-loc))
		     rpos
		     (member rpos (list "s" "n-u" "n" "") :test #'string=))
	    (cond 
	     ((and (gethash rindex h-noun-pos)
		   (member (gethash rindex h-noun-pos)
			   (list "s" "n-u" "n" "") :test #'string=)
		   (not (string= (gethash rindex h-noun-pos) rpos)))
	      (return-from link-pos-dup-rm nil))
	     (t
	      (setf (gethash rindex h-noun-pos-loc) rpos))))))
      ;; assume hash table is passed by reference
      (maphash #'(lambda (k v) (setf (gethash k h-noun-pos) v)) h-noun-pos-loc)
      lt)
     (t
      lt))))

(defmethod l< ((l-1 list) (l-2 list))
  (do ((l1 l-1 (cdr l1))
       (l2 l-2 (cdr l2)))
      ((null l1))
    (let* ((el1 (car l1))
	   (el2 (car l2)))
      (cond 
       ((< el1 el2) (return-from l< t))
       ((> el1 el2) (return-from l< nil)))))
  nil)

(defun biased-link-extract (c-sent l-pnode poss po nparses
				   &key (pos-check? t) (dup-rm? t) (best-only? t)
				   &aux linkage-tables)
  "Auxiliary function, only extract links when nparses > 0.
select linkage with all nearest PP attachment"
  (let* ((h-noun-pos (make-hash-table :test #'equalp)) l-passed-cv l-cv
	 min-cv best-lt best-pnum l-passed-lt l-lt l-passed-pnum l-pnum)
    (dotimes (pnum nparses)
      (with-linkage
       (linkage pnum c-sent po)
       ;; This computes a combined linkage in case the
       ;; sentence/linkage contains conjuncts.
       (linkage_compute_union linkage)
       (let* ((nsublinkages (linkage_get_num_sublinkages linkage))
	      (nlink-cost (- 0 nsublinkages))
	      (dis-cost (linkage_disjunct_cost linkage))
	      (unuse-cost (linkage_unused_word_cost linkage))
	      (and-cost (linkage_and_cost linkage))
	      (fr (linkage_set_current_sublinkage linkage (1- nsublinkages)))
	      (lt (link-pos-check (link-table linkage) pos-check? poss))
	      (pp-cost (PP-dist-sum (or lt (link-table linkage))))
	      (cv (list unuse-cost dis-cost nlink-cost and-cost pp-cost)))
	 (declare (ignorable unuse-cost dis-cost nlink-cost and-cost pp-cost 
			     fr))
	 (when lt
	   (push lt l-passed-lt)
	   (push pnum l-passed-pnum)
	   (push cv l-passed-cv))
	 
	 (push (link-table linkage) l-lt)
	 (push pnum l-pnum)
	 (push cv l-cv))))
    
    (cond
     (l-passed-lt						
      (setf l-passed-lt (nreverse l-passed-lt)
	    l-passed-pnum (nreverse l-passed-pnum)
	    l-passed-cv (nreverse l-passed-cv))
      (when (>= *debug-link-parse* 1)
	(format t "~&pos check filtered: ~a/~a~%" 
		(length l-passed-lt) nparses)))
     (t					  ;; no link table passed pos check
      (setf l-passed-lt (nreverse l-lt)
	    l-passed-pnum (nreverse l-pnum)
	    l-passed-cv (nreverse l-cv))
      (when (>= *debug-link-parse* 1)
	(format t "~&pos check failed: ~a~%" nparses))))
    
    (do ((l-passed-lt l-passed-lt (cdr l-passed-lt))
	 (l-passed-pnum l-passed-pnum (cdr l-passed-pnum))
	 (l-passed-cv l-passed-cv (cdr l-passed-cv)))
	((null l-passed-lt))
      (let* ((lt (car l-passed-lt))
	     (pnum (car l-passed-pnum))
	     (cv (car l-passed-cv)))
	(when (link-pos-dup-rm lt dup-rm? h-noun-pos)
	  (when (>= *debug-link-parse* 2) 
	    (format t "~&linkage table #~a:~%~a~%" (1+ pnum) lt)
	    (format t "~&cost: ~a~%" cv))
	  (cond 
	   (best-only?		      ;; linkage-tables contains only the best
	    (cond
	     (min-cv
	      (when (l< cv min-cv)
		(setf min-cv cv
		      best-lt lt
		      best-pnum pnum)))
	     (t
	      (setf min-cv cv
		    best-lt lt
		    best-pnum pnum))))
	   (t
	    (push lt linkage-tables))))))
    
    (clrhash h-noun-pos)
    (when (and best-only? min-cv)
      (push best-lt linkage-tables)
      (when (>= *debug-link-parse* 1) 
	(format t "~&Cost (UNUSED, DIS, NSUB, AND, PP-LEN): ~a~%" min-cv))
      (with-linkage (linkage best-pnum c-sent po)
		    (linkage_compute_union linkage)
		    (let ((nsublinkages (linkage_get_num_sublinkages linkage)))
		      (linkage_set_current_sublinkage linkage (1- nsublinkages))
		      (let* ((best-dg (linkage_print_diagram linkage)))
			(when (>= *debug-link-parse* 1) 
			  (format t "~&~a~%" (native-to-string best-dg)))
			(linkage_free_diagram best-dg)))))
    
    (unless linkage-tables
      (format t "~&Linkage tables is null.~%")
      (return-from biased-link-extract 0))
    (link-annotate linkage-tables l-pnode)
    (if best-only? 1 nparses)))

(defun typed-biased-link-parse (sent parse-node-type
				     &key (pos-check? t) (best-only? t) 
				     (dup-rm? t) (cap-adjust? t)
				     &aux po nparses sent-str poss l-pnode)
  "Select a linkage with customized bias. The bias is implemented as choosing 
the linkage with the minimum customized cost vector, currently the cost vector
is formed as link parser's default cost vector followed by the PP attachment
cost."
  (assert (equalp (gtype 'gtoken-type) 'lp-token)
	  ()
	  "Why call me if not handling lp-token?")
  (cond 
   ((equalp parse-node-type 'parse-node-link-hier)
    (setf l-pnode (annotations-spec sent :type 'parse-node-link)))
   ((equalp parse-node-type 'parse-node-link-biased)
    (dolist (lpta (annotations-spec sent :type 'lp-token))
      (let* ((doc (document sent)) 
	     (pnode (make-instance 'parse-node-link-biased
				   :document doc
				   :start (start lpta)
				   :end (end lpta)
				   :sw-ver (gsw-ver 'gparse)
				   :setting (gsetting 'gparse)
				   :data (content lpta))))
	(push pnode l-pnode)
	(add-annotation doc pnode)
	(add-annotation sent pnode)))))
  
  (let* ((l-pnode-str (mapcar #'data l-pnode))
	 (l-pos (mapcar #'(lambda (a) 
			    (car (annotations-on-spec a :type (gtype 'gtag-type))))
			(mapcar #'head l-pnode))))
    (setf sent-str (format nil "~{~a~^ ~}" l-pnode-str)
	  poss (mapcar #'(lambda (a) (format nil "~a" (data a))) l-pos))
    (when cap-adjust? (setf sent-str (cap-adjust sent-str)))
    (when (>= *debug-link-parse* 1) 
      (format t "~&sent str is ~%~a~%" sent-str)
      (format t "~&poss seq is: ~%~{~a~^, ~}~%" poss)))
  
  (with-sentence
   (c-sent sent-str *dict*)
   (with-parse-options
    (normal *po-normal*)
    (with-parse-options
     (aggressive *po-aggressive*)
     (with-parse-options
      (panic *po-panic*)
      (multiple-value-bind (val error)
	  (sentence_split c-sent normal)
	(when (or error (minusp val))
	  (format t "~%Can't tokenize: ~a~%due to: ~a~%" c-sent error)
	  (return-from typed-biased-link-parse nil))
	;; shouldn't be here, only for debugging
	(let* ((i 0)
	       w)
	  (dolist (pnode l-pnode) 
	    (incf i)
	    (setf w (sentence_get_word c-sent i))
	    (assert (string-equal w (content pnode))
		    ()
		    "token ~a and word ~a mismatch." pnode w))))
      ;; repeat link-parse, think of better code refactoring
      (setf nparses (ignore-errors (sentence_parse c-sent normal))
	    po normal)
      (when (or (null nparses) (minusp nparses))
	;; nparses can be -1 in case of error
	(format t "~%Error normally parsing ~a." sent-str))
      (unless (and nparses (> nparses 0))
	(parse_options_set_max_null_count
	 aggressive (sentence_length c-sent))
	(setf nparses (ignore-errors (sentence_parse c-sent aggressive))
	      po aggressive)
	(when (or (null nparses) (minusp nparses))
	  (format t "~%Error aggressively parsing ~a." sent-str))
	(unless (and nparses (> nparses 0))
	  (setf nparses (ignore-errors (sentence_parse c-sent panic))
		po panic)
	  (when (or (null nparses) (minusp nparses))
	    (format t "~%Error panically parsing ~a." sent-str))))
      ;; realignment	      
      (cond
       ((or (null nparses) (minusp nparses))
	;; already reported error
	(return-from typed-biased-link-parse -1))
       ((zerop nparses)
	(format t "~%No parses found for ~s" sent-str)
	(return-from typed-biased-link-parse 0))
       (t 
	(when (>= *debug-link-parse* 1) 
	  (format t "~&Number of linkage is ~a~%" nparses))
	(biased-link-extract c-sent l-pnode poss po nparses :dup-rm? dup-rm?
			     :best-only? best-only? 
			     :pos-check? pos-check?))))))))

(defmethod biased-link-parse ((doc document)
			      &key (best-only? t) (pos-check? t) (dup-rm? t))
  (format t "~&Biased Parsing ~a~%" (name doc))
  ;; Flush alp-related annotations wholesale, not per sentence.
  ;; (flush-annotations doc :type 'parse-node-link)
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (sa (annotations doc :type 'sentence-annotation))
      (format t "~&biased link parse sentence ~a:~%~a~%" (id sa) (content sa))
      (let ((parsed (typed-biased-link-parse sa 'parse-node-link-biased 
					     :best-only? best-only? 
					     :pos-check? pos-check? 
					     :dup-rm? dup-rm?)))
	(cond ((null parsed) (incf n-err))
	      ((and (numberp parsed) (zerop parsed)) (incf n-lose))
	      ((and (numberp parsed) (minusp parsed)) (incf n-skipped))
	      (t (incf n-win)))))
    (add-analysis doc :ganalysis 'gparse)
    (setf (dirty-annotations doc) t) ;; This is necessary!
    (save doc)
    (list n-win n-lose n-err n-skipped)))

(defmethod biased-link-parse ((corp corpus)
			      &key (best-only? t) (pos-check? t) (dup-rm? t))
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (dn (documents corp))
      (let ((result (biased-link-parse (document dn) 
				       :best-only? best-only? 
				       :pos-check? pos-check? 
				       :dup-rm? dup-rm?)))
	(incf n-win (car result))
	(incf n-lose (cadr result))
	(incf n-err (caddr result))
	(incf n-skipped (cadddr result))))
    (list n-win n-lose n-err n-skipped)))


(defmethod hier-link-parse ((sent sentence-annotation)
			    &key (best-only? t) (pos-check? t) (dup-rm? t)
			    &aux sent-str)
  "For hierarchical link parse, parse-node-link corresponds to either an abstracted 
 concept unit or an original sentence token. The 
 span of the astracted token takes the span of the original token(s)
 the abstracted one come from. To prevent data duplication, the original 
 sentence consists of a mixture of original parse-node-links and abstract parse-node-links
 however, parse on original sentence and parse on abstract sentence cannot be
 present at the same time. Need to change it to be more flexible.
Note
======
Assumes that a sentence doesn't have brackets"
  (assert (equalp (gtype 'gparse-node-type) 'parse-node-link-hier)
	  ()
	  "Why calling me if you are not dealing with parse-node-link-hier?")
  (setf sent-str (content sent))
  (format t "hierarchically link parse sentence ~a:~%~a~%" (id sent) sent-str)
  (let* ((doc (document sent))
	 (phrases (annotations-spec sent :type (gtype 'gphrase-type)))
	 ph-type pn l-pos l-pos-str l-tk l-pn-str l-alp-pos-str
	 (num-prn 0) (num-out 0))
    ;; abstract out the sentence, replace long phrases by concept unit
    (dolist (phrase phrases)
      (setf ph-type (data phrase)
	    l-pos (annotations-spec phrase :type (gtype 'gtag-type))	      
	    l-tk (annotations-spec phrase :type 'lp-token))
      (setf l-pos-str (mapcar #'(lambda (x) (format nil "~a" (data x))) l-pos))
      (cond
       ((and (string= "NP" ph-type)
	     ;; not percentage
	     (not (and (member "CD" l-pos-str :test #'string=)
		       (match-re "(%|percent)" (content phrase))))
	     ;; don't trust opennlp's handling with conjunctions so keep it. 
	     ;; e.g.: and, or, but etc.
	     (not (member "CC" l-pos-str :test 'string=))) 
	(dolist (tkstr-pos (abstract-ph phrase)) 
	  (setf pn (make-instance 'parse-node-link-hier 
				  :document doc
				  :start (start phrase)
				  :end (end phrase)
				  :sw-ver (gsw-ver 'gparse)
				  :setting (gsetting 'gparse)
				  :data (car tkstr-pos)))
	  (add-annotation doc pn)
	  (add-annotation sent pn)
	  (push (format nil "~a" (data (cdr tkstr-pos))) l-alp-pos-str)
	  (push (data pn) l-pn-str)))
       
       ((string= "PRN" ph-type)			;; ignore parenthesis for now
	(incf num-prn))

       (t
	(if (string= "OUT" ph-type)
	    (incf num-out))
	(do ((l-tk l-tk (cdr l-tk))
	     (l-pos-str l-pos-str (cdr l-pos-str)))
	    ((null l-tk))
	  (let* ((tok (car l-tk)) 
		 (tok-str (content tok))
		 (pos-str (car l-pos-str)))
	    (setf pn (make-instance 'parse-node-link-hier 
				    :document doc
				    :start (start tok) 
				    :end (end tok)
				    :sw-ver (gsw-ver 'gparse)
				    :setting (gsetting 'gparse)
				    :data tok-str))
	    (add-annotation doc pn)
	    (add-annotation sent pn)
	    (push pos-str l-alp-pos-str)
	    (push tok-str l-pn-str))))))
    
    ;; parse the abstracted sentence, remember that I don't need to tokenize
    (typed-biased-link-parse sent 'parse-node-link-hier :pos-check? pos-check? 
			     :best-only? best-only? :dup-rm? dup-rm?)))


(defmethod hier-link-parse ((doc document)
			    &key (best-only? t) (pos-check? t) (dup-rm? t))
  (format t "~&Hierarchically Parsing ~a~%" doc)
  ;; Flush alp-related annotations wholesale, not per sentence.
  ;; (flush-annotations doc :type 'parse-node-link)
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (sa (annotations doc :type 'sentence-annotation))
      (let ((parsed (hier-link-parse sa :best-only? best-only? 
				     :pos-check? pos-check? :dup-rm? dup-rm?)))
	(cond ((null parsed) (incf n-err))
	      ((and (numberp parsed) (zerop parsed)) (incf n-lose))
	      ((and (numberp parsed) (minusp parsed)) (incf n-skipped))
	      (t (incf n-win)))))
    (add-analysis doc :ganalysis 'gparse) 
    (setf (dirty-annotations doc) t)
    (save doc)
    (list n-win n-lose n-err n-skipped)))

(defmethod hier-link-parse ((corp corpus)
			    &key (best-only? t) (pos-check? t) (dup-rm? t))
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0))
    (dolist (dn (documents corp))
      (let ((result (link-parse (document dn) :best-only? best-only? 
				:pos-check? pos-check? :dup-rm? dup-rm?)))
	(incf n-win (car result))
	(incf n-lose (cadr result))
	(incf n-err (caddr result))
	(incf n-skipped (cadddr result))))
    (list n-win n-lose n-err n-skipped)))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;
;;; Debugging utilities
;;; I didn't adjust those to annotations-spec
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(defun analyze-parses (corpus)
  "Returns a list of three lists:
   1. Document ids of documents that contain no sentences.
   2. Sentence/document ids that contain no parse-node-links. These failed to tokenize.
   3. Sentence/document ids in which each token has no left and right links. These failed to parse."
  (let ((c (corpus corpus))
	(i 0)
	(null-docs nil)
	(null-sents nil)
	(null-parses nil))
    (dolist (d (documents c))
      (when (zerop (mod (incf i) 1000)) (princ "."))
      (let* ((doc (document d))
	     (sents (annotations doc :type 'sentence-annotation)))
	(if (null sents)
	    (push (id doc) null-docs)
	  (dolist (s sents)
	    (let ((toks (annotations s :type 'parse-node-link)))
	      (if (null toks)
		  (push (cons (id s) (id (document s))) null-sents)
		(if (every #'(lambda (tok)
			       (and (null (left-links tok))
				    (null (right-links tok))))
			   toks)
		    (push (cons (id s) (id (document s))) null-parses))))))))
    (list null-docs null-sents null-parses)))

(defun retry-parses (null-parses)
  "Null-parses is a list of pairs of sentence id and document id. Try parsing each of these sentences again."
  (let ((n-win 0) (n-lose 0) (n-err 0) (n-skipped 0) (i 0))
    (when (zerop (mod i 1000))
      (format t "~%~7d: win ~d, lose ~d, err ~d, skipped ~d"
	      (incf i) n-win n-lose n-err n-skipped))
    (dolist (np null-parses)
      (let* ((doc (document (cdr np)))
	     (sent (find-annotation (car np) doc)))
	(let ((parsed (link-parse sent
				  :show? t
				  :flush? t)))
	  (cond ((null parsed) (incf n-err))
		((and (numberp parsed) (zerop parsed)) (incf n-lose))
		((and (numberp parsed) (minusp parsed)) (incf n-skipped))
		(t (save doc) 
		   (incf n-win))))))
    (list n-win n-lose n-err n-skipped)))

(defmethod untokenized? ((sent sentence-annotation))
  (null (annotations sent :type 'parse-node-link)))

(defmethod unparsed? ((sent sentence-annotation))
  (every #'(lambda (tok)
	     (and (null (left-links tok))
		  (null (right-links tok))))
	 (annotations sent :type 'parse-node-link)))

(defmacro do-sents ((s pairs) &body body)
  `(dolist (,s ,pairs)
     (let* ((doc (document (cdr ,s)))
	    (sent (find-annotation (car ,s) doc)))
       ,@body)))

(defun find-untokenized-sentences ()
  (let ((ans
	 (latesql "select s.id from annotations s left join annotations t on s.document_id=t.document_id and t.start>=s.start and t.end <=s.end where t.id is null")))
    ans))

